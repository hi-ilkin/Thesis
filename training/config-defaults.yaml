# Face detector specific config
detector:
  desc: face detector module
  value: MTCNN
sampling_rate:
  desc: detect face at every k frame
  value: 30
margin:
  desc: margin around detected face in pixels
  value: 30
thresholds_mtcnn:
  desc: threshold value for MTCNN detector
  value: [ 0.7, 0.8, 0.8 ]
min_face_size:
  desc: minimum accepted detected face size
  value: 60
image_size:
  desc: size of detection output (square)
  value: 224

# dataset specific config
batch_size:
  desc: Size of each mini-batch. EB0 - 256 too big for Titan
  value: 128
load_pretrained:
  desc: load original pretrained model
  value: true
load_checkpoint:
  desc: continue from checkpoint
  value: false
use_chunks:
  desc: If true, load trainer from .npz chunks, else from images. If chunks enabled, dataloaders will be loaded every time
  value: false

# training configuration
project:
  value: DFDC-test
model_name:
  value: EfficientNetB0-v2
notes:
  desc: Add run specific notes here. Don't forget to delete when starting new run
  value: training by using images instead of npz
resume_from:
  desc: checkpoint to continue from. None if you want start from scracth
  value: None
epochs:
  desc: Number of epochs to train. Should be chunk size * epoch if chunks used
  value: 10
target_size:
  desc: Output size
  value: 2
output_weights:
  desc: output weights for inbalanced dataset
  value: [ 0.2, 0.8 ]
device:
  desc: use of GPU or CPU
  value: cuda
gpus:
  value: 1
precision:
  desc: half or full precision training. 16 and 32 supported
  value: 16
accumulate_grad_batches:
  desc: Accumulates grads every k batches
  value: 1
limit_train_batches:
  desc: limiting training batches per epoch. float - percent, int - batch count. Default 1.0 (all batches)
  value: 5

# optimizers
opt_name:
  desc: Name of optimizer - [Adam, SGD]
  value: Adam

# lr scheduler setup
lr_scheduler:
  desc: Name of the learning rate scheduler - [cyclic, cyclic2, CosineAnnealingWarmRestarts]
  value: cyclic2
lr_min:
  desc: minnimum lr rate
  value: 0.00001
lr_max:
  desc: maximum lr rate
  value: 0.005

## Cyclic specific params
lr_mode:
  desc: Mode for cyclic LR
  value: triangular2
lr_step_size:
  desc: Number of training iterations in the increasing half of a cycle
  value: 400

## CosineAnnealingWarmRestarts specific params
lr_t0:
  desc: Number of iterations for the first restart
  value: 5
lr_tmult:
  desc: A factor increases after a restart
  value: 1

# other
val_freq:
  desc: Frequency of valdiation check with epoch
  value: 1
log_freq:
  desc: Frequency of logging in steps
  value: 10